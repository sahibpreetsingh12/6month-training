{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Intracranial Hemorrhage?\n",
    "*An intracranial hemorrhage (ICH) is a condition in which a blood vessel erupts inside the brain, causing internal bleeding. If not treated correctly and immediately, a brain hemorrhage can be deadly. The type of hemorrhage is usually diagnosed using a CT or MRI scan. Some hemorrhages are also accompanied by cerebral edema – an excess accumulation of fluid in the intracellular or extracellular spaces of the brain.Edema is exceedingly difficult to identify, appearing as a subtle darker area surrounding the hemorrhage; it sometimes requires analysis of multiple sequential scans. Implementation and execution of a successful segmentation model in these situations requires expertise in all computer vision methods – both classical and deep learning based. RSIP Vision leverages both deep learning and classical computer vision techniques to provide a fully automated solution to this segmentation problem.*\n",
    "to know more,watch [this video](https://www.youtube.com/watch?v=7RqjrCSR8TE) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Competition [here](https://www.kaggle.com/c/rsna-intracranial-hemorrhage-detection)\n",
    "\n",
    "## So all the paths are according to  this path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <font color=\"GREEN\"><b> Typically Intracranial  Hemorrhage Detection is segmentation task like the diagram describing below </b></font>\n",
    "\n",
    "![](https://www.rsipvision.com/wp-content/uploads/2018/07/Hemorrhage-Slide.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*source : https://www.rsipvision.com/intracranial-hemorrhage-and-edema-segmentation/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of Intracranial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://pbs.twimg.com/media/BxqqVoyCQAAOE10.png)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Necessary imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.utils import shuffle\n",
    "from os.path import isfile, join\n",
    "import keras\n",
    "\n",
    "# Standard dependencies\n",
    "import cv2\n",
    "import time\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Machine Learning\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import initializers\n",
    "from keras import regularizers\n",
    "from keras import constraints\n",
    "from keras import backend as K\n",
    "from keras.activations import elu\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.engine import Layer, InputSpec\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.layers import Dense, Conv2D, Flatten, GlobalAveragePooling2D, Dropout\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import pydicom\n",
    "\n",
    "import json\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pydicom\n",
    "from keras import layers\n",
    "from keras.callbacks import Callback, ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from tqdm import tqdm\n",
    "\n",
    "  \n",
    "from keras import backend as K\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "efficientnetb0b7-keras-weights\trsna-intracranial-hemorrhage-detection\n"
     ]
    }
   ],
   "source": [
    "!ls ../input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stage_2_train.csv',\n",
       " 'stage_2_test',\n",
       " 'stage_2_train',\n",
       " 'stage_2_sample_submission.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('/kaggle/input/rsna-intracranial-hemorrhage-detection/rsna-intracranial-hemorrhage-detection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = '/kaggle/input/rsna-intracranial-hemorrhage-detection/rsna-intracranial-hemorrhage-detection/'\n",
    "TRAIN_DIR = 'stage_2_train/'\n",
    "TEST_DIR = 'stage_2_test/'\n",
    "train_df = pd.read_csv(BASE_PATH + 'stage_2_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ID_12cadc6af_epidural</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ID_12cadc6af_intraparenchymal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>ID_12cadc6af_intraventricular</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ID_12cadc6af_subarachnoid</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ID_12cadc6af_subdural</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4516837</td>\n",
       "      <td>ID_4a85a3a3f_intraparenchymal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4516838</td>\n",
       "      <td>ID_4a85a3a3f_intraventricular</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4516839</td>\n",
       "      <td>ID_4a85a3a3f_subarachnoid</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4516840</td>\n",
       "      <td>ID_4a85a3a3f_subdural</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4516841</td>\n",
       "      <td>ID_4a85a3a3f_any</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4516842 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    ID  Label\n",
       "0                ID_12cadc6af_epidural      0\n",
       "1        ID_12cadc6af_intraparenchymal      0\n",
       "2        ID_12cadc6af_intraventricular      0\n",
       "3            ID_12cadc6af_subarachnoid      0\n",
       "4                ID_12cadc6af_subdural      0\n",
       "...                                ...    ...\n",
       "4516837  ID_4a85a3a3f_intraparenchymal      0\n",
       "4516838  ID_4a85a3a3f_intraventricular      0\n",
       "4516839      ID_4a85a3a3f_subarachnoid      0\n",
       "4516840          ID_4a85a3a3f_subdural      0\n",
       "4516841               ID_4a85a3a3f_any      0\n",
       "\n",
       "[4516842 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          False\n",
       "1          False\n",
       "2          False\n",
       "3          False\n",
       "4          False\n",
       "           ...  \n",
       "4516837    False\n",
       "4516838    False\n",
       "4516839    False\n",
       "4516840    False\n",
       "4516841    False\n",
       "Name: ID, Length: 4516842, dtype: bool"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.ID == 'ID_6431af929_intraparenchymal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7ff43e0fa048>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(train_df.Label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4260600\n",
       "1     256242\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.Label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As from above 2 cells we can see huge class imbalance problem in this competition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4516842, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Label</th>\n",
       "      <th>filename</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ID_12cadc6af_epidural</td>\n",
       "      <td>0</td>\n",
       "      <td>ID_12cadc6af.png</td>\n",
       "      <td>epidural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ID_12cadc6af_intraparenchymal</td>\n",
       "      <td>0</td>\n",
       "      <td>ID_12cadc6af.png</td>\n",
       "      <td>intraparenchymal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>ID_12cadc6af_intraventricular</td>\n",
       "      <td>0</td>\n",
       "      <td>ID_12cadc6af.png</td>\n",
       "      <td>intraventricular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ID_12cadc6af_subarachnoid</td>\n",
       "      <td>0</td>\n",
       "      <td>ID_12cadc6af.png</td>\n",
       "      <td>subarachnoid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ID_12cadc6af_subdural</td>\n",
       "      <td>0</td>\n",
       "      <td>ID_12cadc6af.png</td>\n",
       "      <td>subdural</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              ID  Label          filename              type\n",
       "0          ID_12cadc6af_epidural      0  ID_12cadc6af.png          epidural\n",
       "1  ID_12cadc6af_intraparenchymal      0  ID_12cadc6af.png  intraparenchymal\n",
       "2  ID_12cadc6af_intraventricular      0  ID_12cadc6af.png  intraventricular\n",
       "3      ID_12cadc6af_subarachnoid      0  ID_12cadc6af.png      subarachnoid\n",
       "4          ID_12cadc6af_subdural      0  ID_12cadc6af.png          subdural"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df = pd.read_csv(BASE_PATH + 'stage_2_sample_submission.csv')\n",
    "\n",
    "train_df['filename'] = train_df['ID'].apply(lambda st: \"ID_\" + st.split('_')[1] + \".png\")\n",
    "train_df['type'] = train_df['ID'].apply(lambda st: st.split('_')[2])\n",
    "sub_df['filename'] = sub_df['ID'].apply(lambda st: \"ID_\" + st.split('_')[1] + \".png\")\n",
    "sub_df['type'] = sub_df['ID'].apply(lambda st: st.split('_')[2])\n",
    "\n",
    "print(train_df.shape)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The original image size from the [EfficientNet paper](https://arxiv.org/pdf/1905.11946.pdf) for EfficientNetB3 is 300x300x3. We are however not bound by this and can use a smaller size if we want. The original image sizes used for every version of EfficientNet are**\n",
    "\n",
    "* EfficientNetB0 - (224, 224, 3)\n",
    "* EfficientNetB1 - (240, 240, 3)\n",
    "* EfficientNetB2 - (260, 260, 3)\n",
    "* EfficientNetB3 - (300, 300, 3)\n",
    "* EfficientNetB4 - (380, 380, 3)\n",
    "* EfficientNetB5 - (456, 456, 3)\n",
    "* EfficientNetB6 - (528, 528, 3)\n",
    "* EfficientNetB7 - (600, 600, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Image: an overview of model architectures and their performance on [ImageNet](http://www.image-net.org/). We can see that EfficientNet achieves state-of-the-art and uses a lot less parameters than most modern CNN architectures.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://warehouse-camo.cmh1.psfhosted.org/acfb05f8a49eb76db65cf17ac4455aa800f1ab37/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f74656e736f72666c6f772f7470752f6d61737465722f6d6f64656c732f6f6666696369616c2f656666696369656e746e65742f6733646f632f706172616d732e706e67)\n",
    "\n",
    "\n",
    "![](https://warehouse-camo.cmh1.psfhosted.org/02731be4faa16b3d9288be054750067e2621f31a/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f74656e736f72666c6f772f7470752f6d61737465722f6d6f64656c732f6f6666696369616c2f656666696369656e746e65742f6733646f632f666c6f70732e706e67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(121232, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ID_0fbf6a978.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ID_d62ec3412.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>ID_cb544194b.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ID_0d62513ec.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ID_fc45b2151.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           filename\n",
       "0  ID_0fbf6a978.png\n",
       "1  ID_d62ec3412.png\n",
       "2  ID_cb544194b.png\n",
       "3  ID_0d62513ec.png\n",
       "4  ID_fc45b2151.png"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.DataFrame(sub_df.filename.unique(), columns=['filename'])\n",
    "print(test_df.shape)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4516842, 4)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2019)\n",
    "sample_files = np.random.choice(os.listdir(BASE_PATH + TRAIN_DIR), 400000)\n",
    "sample_df = train_df[train_df.filename.apply(lambda x: x.replace('.png', '.dcm')).isin(sample_files)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(310498, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>type</th>\n",
       "      <th>filename</th>\n",
       "      <th>any</th>\n",
       "      <th>epidural</th>\n",
       "      <th>intraparenchymal</th>\n",
       "      <th>intraventricular</th>\n",
       "      <th>subarachnoid</th>\n",
       "      <th>subdural</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ID_000012eaf.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ID_000039fa0.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>ID_00008ce3c.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ID_0001dcc25.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ID_0001de0e8.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310493</td>\n",
       "      <td>ID_ffff82e46.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310494</td>\n",
       "      <td>ID_ffff922b9.png</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310495</td>\n",
       "      <td>ID_ffffb670a.png</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310496</td>\n",
       "      <td>ID_ffffcbff8.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310497</td>\n",
       "      <td>ID_fffff9393.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>310498 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "type            filename  any  epidural  intraparenchymal  intraventricular  \\\n",
       "0       ID_000012eaf.png    0         0                 0                 0   \n",
       "1       ID_000039fa0.png    0         0                 0                 0   \n",
       "2       ID_00008ce3c.png    0         0                 0                 0   \n",
       "3       ID_0001dcc25.png    0         0                 0                 0   \n",
       "4       ID_0001de0e8.png    0         0                 0                 0   \n",
       "...                  ...  ...       ...               ...               ...   \n",
       "310493  ID_ffff82e46.png    0         0                 0                 0   \n",
       "310494  ID_ffff922b9.png    1         0                 0                 1   \n",
       "310495  ID_ffffb670a.png    1         0                 0                 0   \n",
       "310496  ID_ffffcbff8.png    0         0                 0                 0   \n",
       "310497  ID_fffff9393.png    0         0                 0                 0   \n",
       "\n",
       "type    subarachnoid  subdural  \n",
       "0                  0         0  \n",
       "1                  0         0  \n",
       "2                  0         0  \n",
       "3                  0         0  \n",
       "4                  0         0  \n",
       "...              ...       ...  \n",
       "310493             0         0  \n",
       "310494             0         0  \n",
       "310495             1         0  \n",
       "310496             0         0  \n",
       "310497             0         0  \n",
       "\n",
       "[310498 rows x 7 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot_df = sample_df[['Label', 'filename', 'type']].drop_duplicates().pivot(\n",
    "    index='filename', columns='type', values='Label').reset_index()\n",
    "print(pivot_df.shape)\n",
    "pivot_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## windowing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Source: https://www.kaggle.com/omission/eda-view-dicom-images-with-correct-windowing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_image(img, window_center,window_width, intercept, slope, rescale=True):\n",
    "\n",
    "    img = (img*slope +intercept)\n",
    "    img_min = window_center - window_width//2\n",
    "    img_max = window_center + window_width//2\n",
    "    img[img<img_min] = img_min\n",
    "    img[img>img_max] = img_max\n",
    "    \n",
    "    if rescale:\n",
    "        # Extra rescaling to 0-1, not in the original notebook\n",
    "        img = (img - img_min) / (img_max - img_min)\n",
    "    \n",
    "    return img\n",
    "    \n",
    "def get_first_of_dicom_field_as_int(x):\n",
    "    #get x[0] as in int is x is a 'pydicom.multival.MultiValue', otherwise get int(x)\n",
    "    if type(x) == pydicom.multival.MultiValue:\n",
    "        return int(x[0])\n",
    "    else:\n",
    "        return int(x)\n",
    "\n",
    "def get_windowing(data):\n",
    "    dicom_fields = [data[('0028','1050')].value, #window center\n",
    "                    data[('0028','1051')].value, #window width\n",
    "                    data[('0028','1052')].value, #intercept\n",
    "                    data[('0028','1053')].value] #slope\n",
    "    return [get_first_of_dicom_field_as_int(x) for x in dicom_fields]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resize 256x256**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_and_resize(filenames, load_dir):    \n",
    "    save_dir = '/kaggle/tmp/'\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    for filename in tqdm(filenames):\n",
    "        try:\n",
    "            path = load_dir + filename\n",
    "            new_path = save_dir + filename.replace('.dcm', '.png')\n",
    "            dcm = pydicom.dcmread(path)\n",
    "            window_center , window_width, intercept, slope = get_windowing(dcm)\n",
    "            img = dcm.pixel_array\n",
    "            img = window_image(img, window_center, window_width, intercept, slope)\n",
    "\n",
    "            resized = cv2.resize(img, (224, 224))\n",
    "            res = cv2.imwrite(new_path, resized)\n",
    "            \n",
    "        except ValueError:\n",
    "            continue\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 93143/121232 [13:34<03:49, 122.51it/s]"
     ]
    }
   ],
   "source": [
    "save_and_resize(filenames=sample_files, load_dir=BASE_PATH + TRAIN_DIR)\n",
    "save_and_resize(filenames=os.listdir(BASE_PATH + TEST_DIR), load_dir=BASE_PATH + TEST_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implementation of EfficientNetB4 for this competition with Keras**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting efficientnet==0.0.4\n",
      "  Downloading https://files.pythonhosted.org/packages/a6/80/f2c098284f7c07491e66af18d9a5fea595d4b507d10c0845275b8d47dc6f/efficientnet-0.0.4.tar.gz\n",
      "Building wheels for collected packages: efficientnet\n",
      "  Building wheel for efficientnet (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for efficientnet: filename=efficientnet-0.0.4-cp36-none-any.whl size=14288 sha256=b52427165a1451c3a32445289619545e929769fa6a97529ef2fde0be8f35c788\n",
      "  Stored in directory: /root/.cache/pip/wheels/5c/34/68/a611a699a28239e964ccf144c0e767cdb5439fee82ec5de6e0\n",
      "Successfully built efficientnet\n",
      "Installing collected packages: efficientnet\n",
      "Successfully installed efficientnet-0.0.4\n"
     ]
    }
   ],
   "source": [
    "!pip install -U efficientnet==0.0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from efficientnet import EfficientNetB4\n",
    "\n",
    "size = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(os.listdir(\"../input/efficientnetb0b7-keras-weights/efficientnet-b3_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "effnet = EfficientNetB4(weights=None, include_top=False, input_shape=(size, size, 3))\n",
    "\n",
    "effnet.load_weights('../input/efficientnetb0b7-keras-weights/efficientnet-b4_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pivot_df is simply sample_df reformatted so that each column is a label (this way, we can use multi-label in our data generator later)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Batch Normalization becomes unstable with small batch sizes (<16) **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Group Normalization(GN) ????"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Group Normalization(GN) divides the channels into groups and computes within each group the mean and variance for normalization. GN’s computation is independent of batch sizes, and its accuracy is stable in a wide range of batch sizes. On ResNet-50 trained in ImageNet, GN has 10.6% lower error than its BN counterpart when using a batch size of 2; when using typical batch sizes, GN is comparably good with batch normalization BN and outperforms other normalization variants. Moreover, GN can be naturally transferred from pre-training to fine-tuning. GN can outperform its BN based counterparts for object detection and segmentation.*\n",
    "\n",
    "to read more visit this link : https://analyticsindiamag.com/alternatives-batch-normalization-deep-learning/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GroupNormalization(Layer):\n",
    "    \"\"\"Group normalization layer\n",
    "    Group Normalization divides the channels into groups and computes within each group\n",
    "    the mean and variance for normalization. GN's computation is independent of batch sizes,\n",
    "    and its accuracy is stable in a wide range of batch sizes\n",
    "    # Arguments\n",
    "        groups: Integer, the number of groups for Group Normalization.\n",
    "        axis: Integer, the axis that should be normalized\n",
    "            (typically the features axis).\n",
    "            For instance, after a `Conv2D` layer with\n",
    "            `data_format=\"channels_first\"`,\n",
    "            set `axis=1` in `BatchNormalization`.\n",
    "        epsilon: Small float added to variance to avoid dividing by zero.\n",
    "        center: If True, add offset of `beta` to normalized tensor.\n",
    "            If False, `beta` is ignored.\n",
    "        scale: If True, multiply by `gamma`.\n",
    "            If False, `gamma` is not used.\n",
    "            When the next layer is linear (also e.g. `nn.relu`),\n",
    "            this can be disabled since the scaling\n",
    "            will be done by the next layer.\n",
    "        beta_initializer: Initializer for the beta weight.\n",
    "        gamma_initializer: Initializer for the gamma weight.\n",
    "        beta_regularizer: Optional regularizer for the beta weight.\n",
    "        gamma_regularizer: Optional regularizer for the gamma weight.\n",
    "        beta_constraint: Optional constraint for the beta weight.\n",
    "        gamma_constraint: Optional constraint for the gamma weight.\n",
    "    # Input shape\n",
    "        Arbitrary. Use the keyword argument `input_shape`\n",
    "        (tuple of integers, does not include the samples axis)\n",
    "        when using this layer as the first layer in a model.\n",
    "    # Output shape\n",
    "        Same shape as input.\n",
    "    # References\n",
    "        - [Group Normalization](https://arxiv.org/abs/1803.08494)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 groups=32,\n",
    "                 axis=-1,\n",
    "                 epsilon=1e-5,\n",
    "                 center=True,\n",
    "                 scale=True,\n",
    "                 beta_initializer='zeros',\n",
    "                 gamma_initializer='ones',\n",
    "                 beta_regularizer=None,\n",
    "                 gamma_regularizer=None,\n",
    "                 beta_constraint=None,\n",
    "                 gamma_constraint=None,\n",
    "                 **kwargs):\n",
    "        super(GroupNormalization, self).__init__(**kwargs)\n",
    "        self.supports_masking = True\n",
    "        self.groups = groups\n",
    "        self.axis = axis\n",
    "        self.epsilon = epsilon\n",
    "        self.center = center\n",
    "        self.scale = scale\n",
    "        self.beta_initializer = initializers.get(beta_initializer)\n",
    "        self.gamma_initializer = initializers.get(gamma_initializer)\n",
    "        self.beta_regularizer = regularizers.get(beta_regularizer)\n",
    "        self.gamma_regularizer = regularizers.get(gamma_regularizer)\n",
    "        self.beta_constraint = constraints.get(beta_constraint)\n",
    "        self.gamma_constraint = constraints.get(gamma_constraint)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        dim = input_shape[self.axis]\n",
    "\n",
    "        if dim is None:\n",
    "            raise ValueError('Axis ' + str(self.axis) + ' of '\n",
    "                             'input tensor should have a defined dimension '\n",
    "                             'but the layer received an input with shape ' +\n",
    "                             str(input_shape) + '.')\n",
    "\n",
    "        if dim < self.groups:\n",
    "            raise ValueError('Number of groups (' + str(self.groups) + ') cannot be '\n",
    "                             'more than the number of channels (' +\n",
    "                             str(dim) + ').')\n",
    "\n",
    "        if dim % self.groups != 0:\n",
    "            raise ValueError('Number of groups (' + str(self.groups) + ') must be a '\n",
    "                             'multiple of the number of channels (' +\n",
    "                             str(dim) + ').')\n",
    "\n",
    "        self.input_spec = InputSpec(ndim=len(input_shape),\n",
    "                                    axes={self.axis: dim})\n",
    "        shape = (dim,)\n",
    "\n",
    "        if self.scale:\n",
    "            self.gamma = self.add_weight(shape=shape,\n",
    "                                         name='gamma',\n",
    "                                         initializer=self.gamma_initializer,\n",
    "                                         regularizer=self.gamma_regularizer,\n",
    "                                         constraint=self.gamma_constraint)\n",
    "        else:\n",
    "            self.gamma = None\n",
    "        if self.center:\n",
    "            self.beta = self.add_weight(shape=shape,\n",
    "                                        name='beta',\n",
    "                                        initializer=self.beta_initializer,\n",
    "                                        regularizer=self.beta_regularizer,\n",
    "                                        constraint=self.beta_constraint)\n",
    "        else:\n",
    "            self.beta = None\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        input_shape = K.int_shape(inputs)\n",
    "        tensor_input_shape = K.shape(inputs)\n",
    "\n",
    "        # Prepare broadcasting shape.\n",
    "        reduction_axes = list(range(len(input_shape)))\n",
    "        del reduction_axes[self.axis]\n",
    "        broadcast_shape = [1] * len(input_shape)\n",
    "        broadcast_shape[self.axis] = input_shape[self.axis] // self.groups\n",
    "        broadcast_shape.insert(1, self.groups)\n",
    "\n",
    "        reshape_group_shape = K.shape(inputs)\n",
    "        group_axes = [reshape_group_shape[i] for i in range(len(input_shape))]\n",
    "        group_axes[self.axis] = input_shape[self.axis] // self.groups\n",
    "        group_axes.insert(1, self.groups)\n",
    "\n",
    "        # reshape inputs to new group shape\n",
    "        group_shape = [group_axes[0], self.groups] + group_axes[2:]\n",
    "        group_shape = K.stack(group_shape)\n",
    "        inputs = K.reshape(inputs, group_shape)\n",
    "\n",
    "        group_reduction_axes = list(range(len(group_axes)))\n",
    "        group_reduction_axes = group_reduction_axes[2:]\n",
    "\n",
    "        mean = K.mean(inputs, axis=group_reduction_axes, keepdims=True)\n",
    "        variance = K.var(inputs, axis=group_reduction_axes, keepdims=True)\n",
    "\n",
    "        inputs = (inputs - mean) / (K.sqrt(variance + self.epsilon))\n",
    "\n",
    "        # prepare broadcast shape\n",
    "        inputs = K.reshape(inputs, group_shape)\n",
    "        outputs = inputs\n",
    "\n",
    "        # In this case we must explicitly broadcast all parameters.\n",
    "        if self.scale:\n",
    "            broadcast_gamma = K.reshape(self.gamma, broadcast_shape)\n",
    "            outputs = outputs * broadcast_gamma\n",
    "\n",
    "        if self.center:\n",
    "            broadcast_beta = K.reshape(self.beta, broadcast_shape)\n",
    "            outputs = outputs + broadcast_beta\n",
    "\n",
    "        outputs = K.reshape(outputs, tensor_input_shape)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'groups': self.groups,\n",
    "            'axis': self.axis,\n",
    "            'epsilon': self.epsilon,\n",
    "            'center': self.center,\n",
    "            'scale': self.scale,\n",
    "            'beta_initializer': initializers.serialize(self.beta_initializer),\n",
    "            'gamma_initializer': initializers.serialize(self.gamma_initializer),\n",
    "            'beta_regularizer': regularizers.serialize(self.beta_regularizer),\n",
    "            'gamma_regularizer': regularizers.serialize(self.gamma_regularizer),\n",
    "            'beta_constraint': constraints.serialize(self.beta_constraint),\n",
    "            'gamma_constraint': constraints.serialize(self.gamma_constraint)\n",
    "        }\n",
    "        base_config = super(GroupNormalization, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace all Batch Normalization layers by Group Normalization layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i, layer in enumerate(effnet.layers):\n",
    "    if \"batch_normalization\" in layer.name:\n",
    "        effnet.layers[i] = GroupNormalization(groups=32, axis=-1, epsilon=0.00001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BCE DICE LOSS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.losses import binary_crossentropy\n",
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return 1. - score\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras-rectified-adam\n",
      "  Downloading https://files.pythonhosted.org/packages/21/79/9521f66b92186702cb58a214c1b923b416266381cd824e15a1733f6a5b06/keras-rectified-adam-0.17.0.tar.gz\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from keras-rectified-adam) (1.16.4)\n",
      "Requirement already satisfied: Keras in /opt/conda/lib/python3.6/site-packages (from keras-rectified-adam) (2.3.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /opt/conda/lib/python3.6/site-packages (from Keras->keras-rectified-adam) (1.0.8)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.6/site-packages (from Keras->keras-rectified-adam) (1.1.0)\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.6/site-packages (from Keras->keras-rectified-adam) (2.9.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.6/site-packages (from Keras->keras-rectified-adam) (5.1.2)\n",
      "Requirement already satisfied: scipy>=0.14 in /opt/conda/lib/python3.6/site-packages (from Keras->keras-rectified-adam) (1.2.1)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from Keras->keras-rectified-adam) (1.12.0)\n",
      "Building wheels for collected packages: keras-rectified-adam\n",
      "  Building wheel for keras-rectified-adam (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for keras-rectified-adam: filename=keras_rectified_adam-0.17.0-cp36-none-any.whl size=14781 sha256=3af1f28a07e9107753ef9fef3c14a8219eec52f837ba8334600de4260114e7b3\n",
      "  Stored in directory: /root/.cache/pip/wheels/7b/01/27/3a934e1a5644f5b93c720422a6ef97034ea78a21ba71cfb549\n",
      "Successfully built keras-rectified-adam\n",
      "Installing collected packages: keras-rectified-adam\n",
      "Successfully installed keras-rectified-adam-0.17.0\n"
     ]
    }
   ],
   "source": [
    "!pip install keras-rectified-adam\n",
    "from keras_radam import RAdam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    \"\"\"\n",
    "    A custom implementation of EfficientNetB4\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(effnet)\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(6, activation='sigmoid'))\n",
    "    model.compile(loss=bce_dice_loss,\n",
    "                  optimizer=RAdam(warmup_proportion=0.1,lr=0.00005), \n",
    "                  metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "efficientnet-b4 (Model)      (None, 7, 7, 1792)        17423416  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 10758     \n",
      "=================================================================\n",
      "Total params: 17,434,174\n",
      "Trainable params: 17,434,174\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image, sigmaX=10):\n",
    "    \"\"\"\n",
    "    The whole preprocessing pipeline:\n",
    "    1. Read in image\n",
    "    2. Apply masks\n",
    "    3. Resize image to desired size\n",
    "    4. Add Gaussian noise to increase Robustness\n",
    "    \"\"\"\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = crop_image_from_gray(image)\n",
    "    image = cv2.resize(image, (size, size))\n",
    "    image = cv2.addWeighted (image,4, cv2.GaussianBlur(image, (0,0) ,sigmaX), -4, 128)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention please\n",
    "\n",
    "keras team updated their utils.py file from keras-preprocessing github repository just 2 days ago(probably in 26th september,2019) (here:https://github.com/keras-team/keras-preprocessing/blob/master/keras_preprocessing/image/utils.py) so if you try to import and use ImageDataGenerator  old from keras.preprocessing.image import ImageDataGenerator then you will get error saying \"ValueError: Invalid class_mode: other; expected one of: {'input', 'raw', None, 'multi_output', 'binary', 'sparse', 'categorical'}\"\n",
    "\n",
    "i got that error and spend few times on google to figure that out and solved it eventually\n",
    "\n",
    "**Solution : **\n",
    "\n",
    "as the keras-team just updated their utils file to use ImageDataGenerator now you will need to do !pip install git+https://github.com/keras-team/keras-preprocessing.git first then import ImageDataGenerator like this : from keras.preprocessing.image import ImageDataGenerator\n",
    "so, instead of previous keras.preprocessing.image we need to use keras_preprocessing.image now,lets do it ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/keras-team/keras-preprocessing.git\n",
      "  Cloning https://github.com/keras-team/keras-preprocessing.git to /tmp/pip-req-build-v7r6dnem\n",
      "  Running command git clone -q https://github.com/keras-team/keras-preprocessing.git /tmp/pip-req-build-v7r6dnem\n",
      "Requirement already satisfied (use --upgrade to upgrade): Keras-Preprocessing==1.1.0 from git+https://github.com/keras-team/keras-preprocessing.git in /opt/conda/lib/python3.6/site-packages\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.6/site-packages (from Keras-Preprocessing==1.1.0) (1.16.4)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from Keras-Preprocessing==1.1.0) (1.12.0)\n",
      "Building wheels for collected packages: Keras-Preprocessing\n",
      "  Building wheel for Keras-Preprocessing (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for Keras-Preprocessing: filename=Keras_Preprocessing-1.1.0-cp36-none-any.whl size=42211 sha256=5719f386db6cdb86052a90785a13b31ab90732959303738016550c2181b1afab\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-bp83mh6b/wheels/03/a0/39/171f6040d36f36c71168dc69afa81334351b20955dc36ce932\n",
      "Successfully built Keras-Preprocessing\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/keras-team/keras-preprocessing.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/keras_preprocessing/image/dataframe_iterator.py:273: UserWarning: Found 1 invalid image filename(s) in x_col=\"filename\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 263923 validated image filenames.\n",
      "Found 46574 validated image filenames.\n",
      "Found 727392 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "def create_datagen():\n",
    "    return ImageDataGenerator(validation_split=0.15)\n",
    "\n",
    "def create_test_gen():\n",
    "    return ImageDataGenerator().flow_from_dataframe(\n",
    "        sub_df,\n",
    "        directory=  '/kaggle/tmp/',\n",
    "        x_col='filename',\n",
    "        class_mode=None,\n",
    "        target_size=(size, size),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "def create_flow(datagen, subset):\n",
    "    return datagen.flow_from_dataframe(\n",
    "        pivot_df, \n",
    "        directory='/kaggle/tmp/',\n",
    "        \n",
    "        x_col='filename', \n",
    "        y_col=['any', 'epidural', 'intraparenchymal', \n",
    "               'intraventricular', 'subarachnoid', 'subdural'],\n",
    "        class_mode='other',\n",
    "        target_size=(size, size),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        preprocessing_function=preprocess_image,\n",
    "        rotation_range=360,\n",
    "        horizontal_flip=True,\n",
    "        validation_split=0.15,\n",
    "        rescale=1 / 128.,\n",
    "        subset=subset\n",
    "    )\n",
    "\n",
    "# Using original generator\n",
    "data_generator = create_datagen()\n",
    "train_gen = create_flow(data_generator, 'training')\n",
    "val_gen = create_flow(data_generator, 'validation')\n",
    "test_gen = create_test_gen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "3125/3125 [==============================] - 1869s 598ms/step - loss: 0.8320 - accuracy: 0.7276 - val_loss: 0.3880 - val_accuracy: 0.6264\n"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint(\n",
    "    'effnetb4.h5', \n",
    "    monitor='val_loss', \n",
    "    verbose=0, \n",
    "    save_best_only=True, \n",
    "    save_weights_only=False,\n",
    "    mode='auto'\n",
    ")\n",
    "#train_length = len(train_df)\n",
    "total_steps = sample_files.shape[0] // BATCH_SIZE\n",
    "total_steps = total_steps // 4\n",
    "history = model.fit_generator(\n",
    "    train_gen,\n",
    "    steps_per_epoch = total_steps,\n",
    "    validation_data=val_gen,\n",
    "    validation_steps=total_steps * 0.15,\n",
    "    callbacks=[checkpoint],\n",
    "    epochs=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**submission**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15299/22731 [===================>..........] - ETA: 16:05"
     ]
    }
   ],
   "source": [
    "model.load_weights('effnetb4.h5')\n",
    "y_test = model.predict_generator(\n",
    "    test_gen,\n",
    "    steps=len(test_gen),\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append the output predicts in the wide format to the y_test\n",
    "test_df = test_df.join(pd.DataFrame(y_test, columns=[\n",
    "    'any', 'epidural', 'intraparenchymal', 'intraventricular', 'subarachnoid', 'subdural'\n",
    "]))\n",
    "\n",
    "# Unpivot table, i.e. wide (N x 6) to long format (6N x 1)\n",
    "test_df = test_df.melt(id_vars=['filename'])\n",
    "\n",
    "# Combine the filename column with the variable column\n",
    "test_df['ID'] = test_df.filename.apply(lambda x: x.replace('.png', '')) + '_' + test_df.variable\n",
    "test_df['Label'] = test_df['value']\n",
    "\n",
    "test_df[['ID', 'Label']].to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Plans\n",
    "\n",
    "1. trying focal instead of bce dice\n",
    "2. using equal number of positive and negative samples for training\n",
    "3. using bit more large size images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****I hope this kernel helpful and some <font color=\"RED\"><b>UPVOTES</b></font> would be very much appreciated******"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**REFERENCES**\n",
    "\n",
    "- https://www.kaggle.com/xhlulu/rsna-intracranial-simple-densenet-in-keras\n",
    "- https://www.kaggle.com/carlolepelaars/efficientnetb5-with-keras-aptos-2019\n",
    "- https://www.kaggle.com/marcovasquez/basic-eda-data-visualization\n",
    "- https://www.kaggle.com/allunia/rsna-ih-detection-eda-baseline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
