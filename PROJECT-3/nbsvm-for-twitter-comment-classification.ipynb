{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/nlp-getting-started/train.csv\n/kaggle/input/nlp-getting-started/test.csv\n/kaggle/input/nlp-getting-started/sample_submission.csv\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/nlp-getting-started/train.csv')\ntest = pd.read_csv('/kaggle/input/nlp-getting-started/test.csv')\nsubm = pd.read_csv('/kaggle/input/nlp-getting-started/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"subm.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp=train.copy()\n\n\nfor j,i in enumerate(train.target):\n    if i==1:\n        temp.set_value(j,'positive',1)\n        temp.set_value(j,'negative',0)\n    else:\n        temp.set_value(j,'positive',0)\n        temp.set_value(j,'negative',1)\n        \n        \ntemp['positive'].fillna(0,inplace=True)\ntemp['negative'].fillna(1,inplace=True)\ntemp.head(30)\ntrain=temp.copy()\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"COMMENT = 'text'\ntrain[COMMENT].fillna(\"unknown\", inplace=True)\ntest[COMMENT].fillna(\"unknown\", inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re, string\nre_tok = re.compile(f'([{string.punctuation}“”¨«»®´·º½¾¿¡§£₤‘’])')\ndef tokenize(s): return re_tok.sub(r' \\1 ', s).split()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n = train.shape[0]\nvec = TfidfVectorizer(ngram_range=(1,2), tokenizer=tokenize,\n               min_df=3, max_df=0.9, strip_accents='unicode', use_idf=1,\n               smooth_idf=1, sublinear_tf=1 )\ntrn_term_doc = vec.fit_transform(train[COMMENT])\ntest_term_doc = vec.transform(test[COMMENT])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trn_term_doc, test_term_doc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = trn_term_doc\ntest_x = test_term_doc\ndef pr(y_i, y):\n    p = x[y==y_i].sum(0)\n    return (p+1) / ((y==y_i).sum()+1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_mdl(y):\n    y = y.values\n    r = np.log(pr(1,y) / pr(0,y))\n    m = LogisticRegression(C=4)\n    x_nb = x.multiply(r)\n    return m.fit(x_nb, y), r","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label_cols=['positive','negative']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = np.zeros((len(test), len(label_cols)))\n\nfor i, j in enumerate(label_cols):\n    print('fit', j)\n    m,r = get_mdl(train[j])\n    preds[:,i] = m.predict_proba(test_x.multiply(r))[:,1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target=[] 3 to get all the target values of classifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submid = pd.DataFrame({'id': subm[\"id\"]})\nfor i in range(len(preds)):\n    if preds[i][0]>preds[i][1]:\n        target.append(1)\n    else:\n        target.append(0)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submid['target']=target\n\nsubmid.to_csv('submission.csv', index=False)\nsubmid.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Mini Example Below to understand whole process"},{"metadata":{},"cell_type":"markdown","source":"# Training Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"checker=pd.DataFrame({'Text':['He is playing positively',\n                             'He is playing negatively',\n                             'He playing positively'],\n                     'positive':[1,0,1],\n                     'negative':[0,1,0]})\nchecker.head()","execution_count":2,"outputs":[{"output_type":"execute_result","execution_count":2,"data":{"text/plain":"                       Text  positive  negative\n0  He is playing positively         1         0\n1  He is playing negatively         0         1\n2     He playing positively         1         0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>positive</th>\n      <th>negative</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>He is playing positively</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>He is playing negatively</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>He playing positively</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Test Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"checker_test=pd.DataFrame({'Text':['He is playing positively',\n                             'she is  negatively'],\n                     })","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vec = TfidfVectorizer(ngram_range=(1,2),\n               min_df=1, max_df=0.9, strip_accents='unicode', use_idf=1,\n               smooth_idf=1, sublinear_tf=1 )\ntokenised_text=vec.fit_transform(checker['Text'])\nprint(vec.get_feature_names())\n\ntest_data=vec.transform(checker_test['Text'])","execution_count":4,"outputs":[{"output_type":"stream","text":"['he is', 'he playing', 'is', 'is playing', 'negatively', 'playing negatively', 'playing positively', 'positively']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(tokenised_text.shape)\nprint('\\n')\nprint(tokenised_text.todense()[0])\nprint('\\n')\nprint(tokenised_text.todense()[2])\n","execution_count":5,"outputs":[{"output_type":"stream","text":"(3, 8)\n\n\n[[0.4472136 0.        0.4472136 0.4472136 0.        0.        0.4472136\n  0.4472136]]\n\n\n[[0.         0.68091856 0.         0.         0.         0.\n  0.51785612 0.51785612]]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(x.todense())","execution_count":13,"outputs":[{"output_type":"stream","text":"[[0.4472136  0.         0.4472136  0.4472136  0.         0.\n  0.4472136  0.4472136 ]\n [0.3935112  0.         0.3935112  0.3935112  0.51741994 0.51741994\n  0.         0.        ]\n [0.         0.68091856 0.         0.         0.         0.\n  0.51785612 0.51785612]]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"x=tokenised_text\ndef pr(y_i, y):\n    print(y_i==y)\n    print('\\n')\n    p = x[y==y_i].sum(0)\n    print(p)\n    return (p+1) / ((y==y_i).sum()+1)\n","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_mdl(y):\n    y = y.values\n    print('Values are',y)\n    r = np.log(pr(1,y) / pr(0,y))\n    print(r,\"\\n\")\n    m = LogisticRegression(C=4)\n    x_nb = x.multiply(r)\n    print(\"We are \",x_nb.todense())\n    return m.fit(x_nb, y), r","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label_cols=['positive','negative']\npreds = np.zeros((len(checker_test), len(label_cols)))\n\nfor i, j in enumerate(label_cols):\n    print('fit', j)\n    m,r = get_mdl(checker[j])\n    preds[:,i] = m.predict_proba(test_data.multiply(r))[:,1]","execution_count":21,"outputs":[{"output_type":"stream","text":"fit positive\nValues are [1 0 1]\n[ True False  True]\n\n\n[[0.4472136  0.68091856 0.4472136  0.4472136  0.         0.\n  0.96506971 0.96506971]]\n[False  True False]\n\n\n[[0.3935112  0.         0.3935112  0.3935112  0.51741994 0.51741994\n  0.         0.        ]]\n[[-0.36765167  0.1138753  -0.36765167 -0.36765167 -0.8224766  -0.8224766\n   0.27006261  0.27006261]] \n\nWe are  [[-0.16441882  0.         -0.16441882 -0.16441882  0.          0.\n   0.12077567  0.12077567]\n [-0.14467505  0.         -0.14467505 -0.14467505 -0.42556579 -0.42556579\n   0.          0.        ]\n [ 0.          0.0775398   0.          0.          0.          0.\n   0.13985358  0.13985358]]\nfit negative\nValues are [0 1 0]\n[False  True False]\n\n\n[[0.3935112  0.         0.3935112  0.3935112  0.51741994 0.51741994\n  0.         0.        ]]\n[ True False  True]\n\n\n[[0.4472136  0.68091856 0.4472136  0.4472136  0.         0.\n  0.96506971 0.96506971]]\n[[ 0.36765167 -0.1138753   0.36765167  0.36765167  0.8224766   0.8224766\n  -0.27006261 -0.27006261]] \n\nWe are  [[ 0.16441882  0.          0.16441882  0.16441882  0.          0.\n  -0.12077567 -0.12077567]\n [ 0.14467505  0.          0.14467505  0.14467505  0.42556579  0.42556579\n   0.          0.        ]\n [ 0.         -0.0775398   0.          0.          0.          0.\n  -0.13985358 -0.13985358]]\n","name":"stdout"}]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}